{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/juanhuguetgarcia/intro_to_llms/blob/main/intro_to_llms/2_langgraph_our_calculator_agent.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_4Iatn6mmxJ"
   },
   "source": [
    "# ðŸ§‘â€ðŸ« Tutorial: Building Your First AI Agent with LangGraph, LangChain & Pydantic\n",
    "\n",
    "Hereâ€™s a step-by-step interactive guide to understand how to build our first AI agent using:\n",
    "\n",
    "* ðŸ§  LangChain for agent logic\n",
    "* ðŸ” LangGraph for orchestration\n",
    "* ðŸ“¦ Pydantic for clean state structure\n",
    "* ðŸ§® Calculator tool for real functionality\n",
    "\n",
    "In this notebook, weâ€™re going to build a simple AI agent that can answer math questions like:\n",
    "\n",
    "â€œWhat is 24 * 3?â€\n",
    "\n",
    "Weâ€™ll do it step by step. Hereâ€™s what weâ€™re going to do:\n",
    "\n",
    "## ðŸ§± Step 1: Define What Our Agent Needs to Know (the â€œstateâ€)\n",
    "\n",
    "Weâ€™ll create a little box of information (called state) where we put:\n",
    "* the question we ask (input)\n",
    "* the answer the agent gives us (output)\n",
    "\n",
    "To keep things clean and organized, weâ€™ll use a little helper called Pydantic.\n",
    "Think of it like a smart checklist that makes sure our box always has the right items.\n",
    "\n",
    "## ðŸ”¢ Step 2: Create a Typed Calculator Tool Using @tool\n",
    "\n",
    "Instead of passing in a string like \"24 * 3\" and parsing it with eval, weâ€™re going to build a real Python function that accepts two numbers and returns the result.\n",
    "\n",
    "LangChain allows us to turn any function into an AI tool using a special decorator called @tool.\n",
    "\n",
    "## ðŸ¤– Step 3: Build the Agent\n",
    "\n",
    "Weâ€™ll connect the tool to an AI model using LangChain. The AI will be smart enough to:\n",
    "* read the question,\n",
    "* choose the calculator if needed,\n",
    "* return the answer.\n",
    "\n",
    "This is the brain of our agent.\n",
    "\n",
    "## ðŸ”„ Step 4: Create a Graph (Flow)\n",
    "\n",
    "Weâ€™ll then tell LangGraph:\n",
    "\tâ€¢\twhere to start,\n",
    "\tâ€¢\twhat steps to follow,\n",
    "\tâ€¢\tand where to end.\n",
    "\n",
    "This is like drawing a simple flowchart:\n",
    "â†’ Get the question â†’ Use the agent â†’ Return the answer\n",
    "\n",
    "## â–¶ï¸ Step 5: Run It!\n",
    "\n",
    "Finally, weâ€™ll give it a question like \"What is 12 * 6?\", and watch the agent respond with the right answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJVSj-7QMPHR"
   },
   "source": [
    "# Install required packages\n",
    "\n",
    "Packages required: langgraph, langchain_openai and langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyMnVAh9-XzD",
    "outputId": "6ea4fc17-25d0-43c2-f335-06d23ff29daa"
   },
   "outputs": [],
   "source": [
    "# Install LangGraph and langchain packages\n",
    "%pip install --quiet -U langgraph langchain_openai langchain_core python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmpdeLEQnKSO"
   },
   "source": [
    "## Set Open AI Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the api key in the .env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FRkJRQ2lowz",
    "outputId": "a025c6b0-58fb-4cff-8884-cbd13a044ab4"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get(\"OPENAI_API_KEY\")[:10] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zqxPqBomDdW"
   },
   "source": [
    "### ðŸ§± Step 1: Define What Our Agent Needs to Know (the â€œstateâ€)\n",
    "Weâ€™ll create a little box of information (called state) where we put:\n",
    "\n",
    "* the question we ask (input_msg)\n",
    "\n",
    "* the answer the agent gives us (output_msg)\n",
    "\n",
    "To keep things clean and organized, weâ€™ll use a little helper called Pydantic. Think of it like a smart checklist that makes sure our box always has the right items.\n",
    "\n",
    "ðŸ§  Why Pydantic?\n",
    "* Provides type safety and autocomplete in editors\n",
    "* Ensures clean, validated state\n",
    "* Avoids messy dicts and typos\n",
    "* **LangGraph supports it natively for StateGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Union\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    input: ...\n",
    "    output: ... = \"\"  # this will be updated after tool execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that pydantic is giving us a nice representation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass input and output strings to the AgentState model\n",
    "\n",
    "print(AgentState(...).model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¢ Step 2: Create a Typed Calculator Tool Using @tool\n",
    "\n",
    "Instead of passing in a string like \"24 * 3\" and parsing it with eval, weâ€™re going to build a real Python function that accepts two numbers and returns the result.\n",
    "\n",
    "LangChain allows us to turn any function into an AI tool using a special decorator called @tool\n",
    "\n",
    "ðŸ§  Why Use @tool?\n",
    "\n",
    "Using @tool is:\n",
    "* ðŸ” Safe â€” no risky parsing or code execution like eval\n",
    "* ðŸ§¼ Clean â€” LangChain will automatically read:\n",
    "- the function name (calculate)\n",
    "- the parameter names and types (a: int, b: int)\n",
    "- the docstring to describe the tool\n",
    "- ðŸ¤– Agent-friendly â€” the agent will now know exactly how to use this tool: â€œIf I get a question like â€˜What is 5 plus 7?â€™, I can call calculate(a=5, b=7).â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wt7Ur592QPC"
   },
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "@tool\n",
    "def calculate(a: int, b: int) -> str:\n",
    "    \"\"\"...\"\"\"\n",
    "    return str(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how it actually it adds a pydantic model with the metadata..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(calculate.args_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤– Step 3: Build the Agent\n",
    "\n",
    "Now that we have a proper tool defined, letâ€™s create the agent that knows how to use it.\n",
    "\n",
    "ðŸ§  Whatâ€™s Going On Here?\n",
    "\n",
    "Initialize_agent sets up a reasoning agent that knows how to:\n",
    "\n",
    "* Interpret your question\n",
    "* Decide whether a tool is needed\n",
    "* Call that tool with the right parameters\n",
    "* Return the final answer\n",
    "* `AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION` is perfect for functions with multiple inputs:\n",
    "    * It uses tool descriptions and the prompt itself to choose actions\n",
    "    * No need to hard-code logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "# Create the LLM (you can replace with any compatible model)\n",
    "llm = ChatOpenAI(model=\"...\", temperature=...)\n",
    "\n",
    "# Initialize the agent with our tool\n",
    "agent_executor = initialize_agent(\n",
    "    tools=[..., ],\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§  Step 5: Create a Node That Runs the Agent\n",
    "\n",
    "In LangGraph, we wrap each step in a function that takes the current state, does something, and returns the updated state.\n",
    "\n",
    "ðŸ’¡ Reminder: Whatâ€™s â€œStateâ€?\n",
    "\n",
    "Think of AgentState as a box that carries:\n",
    "* input: what the user asked\n",
    "* output: what the agent answered\n",
    "\n",
    "Each LangGraph node receives the box, modifies it, and passes it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we have defined the AgentState above\n",
    "\n",
    "# Node that runs the agent. This is a langchain runnable, so it could be as well the RAG we did last session\n",
    "def run_agent(state: AgentState) -> AgentState:\n",
    "    result = agent_executor.run(state.input)\n",
    "    return AgentState(input=state.input, output=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b_pwEWMuE8i"
   },
   "source": [
    "## Create the Graph\n",
    "\n",
    "Create a node that calls LLM\n",
    "\n",
    "As there are no other nodes, we will connect the START and the END to this node and compile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding LangGraph Components\n",
    "\n",
    "ðŸ§  Why Use a Graph Here?\n",
    "\n",
    "LangGraph lets us define structured flows:\n",
    "\n",
    "* In this example, itâ€™s a single-node graph\n",
    "* Later, we can add conditional branches, tools, memory, retries, etc.\n",
    "* It also gives us visualization and execution tracing for free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2lFrsS4BWda"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add our only node: the agent itself\n",
    "graph.add_node(\"agent\", run_agent)\n",
    "\n",
    "# Define the flow: start at the agent, then end\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_edge(\"agent\", END)\n",
    "\n",
    "# Compile it\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrvhiT5ruwKx"
   },
   "source": [
    "## Visualize the graph\n",
    "\n",
    "Visualize the graph using display() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "M6muQWGKDCGw",
    "outputId": "19cd40a4-991a-42de-e800-ac235a696bc0"
   },
   "outputs": [],
   "source": [
    "# Visualize your graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PbsLdntvAcl"
   },
   "source": [
    "# Test\n",
    "\n",
    "Test the graph using app.invoke() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"input\": \"What is 13 plus 29?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Recap\n",
    "\n",
    "You just built a real AI agent that can:\n",
    "* Understand natural language\n",
    "* Choose a Python tool to use\n",
    "* Return accurate results\n",
    "\n",
    "You used:\n",
    "* Pydantic to structure state\n",
    "* LangChain to build the agent\n",
    "* LangGraph to control the flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s add a second tool and introduce branching logic in the graph so your students can learn how LangGraph routes input based on content.\n",
    "\n",
    "## ðŸŽ¯ Goal\n",
    "\n",
    "* Add a second tool: get_time() â†’ returns the current time.\n",
    "* Add a classifier node that decides:\n",
    "    * If the question is about math â†’ use the calculator agent\n",
    "    * If the question is about time â†’ use the time tool\n",
    "\n",
    "Use add_conditional_edges to route input based on type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_time() -> str:\n",
    "    \"\"\"Returns the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  2. Update Agent Tool List\n",
    "\n",
    "Update the agent with both tools (note: only calculate needs structured input):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = initialize_agent(\n",
    "    tools=[calculate, get_time],\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  3. Define a Classifier Node\n",
    "\n",
    "This node routes inputs to the correct node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentStateBranch(BaseModel):\n",
    "    input: str\n",
    "    output: str = \"\"\n",
    "    branch: Literal[\"math\",\"time\"] = \"math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def classify_question(state: AgentStateBranch) -> AgentStateBranch:\n",
    "    text = state.input.lower()\n",
    "    if \"time\" in text:\n",
    "        branch = \"time\"\n",
    "    else:\n",
    "        branch = \"math\"\n",
    "    return AgentState(\n",
    "      input=state.input,\n",
    "      output=state.output,\n",
    "      branch=branch\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ 4. Define a Time Tool Node\n",
    "\n",
    "We wrap the get_time() tool into a node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_time_tool(state: AgentStateBranch) -> AgentStateBranch:\n",
    "    result = get_time.invoke({})\n",
    "    return AgentState(input=state.input, output=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build the LangGraph with Branching\n",
    "graph = StateGraph(AgentStateBranch)\n",
    "\n",
    "# Nodes\n",
    "graph.add_node(\"classify\", classify_question)\n",
    "graph.add_node(\"math_agent\", run_agent)\n",
    "graph.add_node(\"time_tool\", run_time_tool)\n",
    "\n",
    "# Flow\n",
    "graph.add_edge(START, \"classify\")  # âœ… Kick off at START\n",
    "graph.add_conditional_edges(\"classify\", lambda s: s.branch, {\n",
    "    \"math\": \"math_agent\",\n",
    "    \"time\": \"time_tool\"\n",
    "})\n",
    "\n",
    "graph.add_edge(\"math_agent\", END)\n",
    "graph.add_edge(\"time_tool\", END)\n",
    "\n",
    "# Compile\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app.invoke({\"input\": \"What is 6 + 9?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app.invoke({\"input\": \"What time is it ?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
